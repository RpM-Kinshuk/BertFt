{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to save raw data from .npy files to .csv files\n",
    "\n",
    "# Plot validation loss on x axis for different layers for each epoch\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "tasks = ['cola', 'mrpc', 'qnli', 'rte', 'sst2', 'stsb']\n",
    "alpha_asc = ['True', 'False']\n",
    "epochs = 3\n",
    "layers = [0, 1, 2, 3, 4, 5, 6, 8, 10, 12, 18, 24, 30, 36, 72, 74]\n",
    "\n",
    "dictionary = {\n",
    "    'False': {'first_val_loss':[],\n",
    "    \"first_val_acc\":[]},\n",
    "    'True': {'first_val_loss':[],\n",
    "    \"first_val_acc\":[]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Ebooks\\code\\BertFt\n",
      "{'False': {'first_val_loss': array([[8.59665425, 1.76494619, 1.66819267, 1.52187856, 1.45744146,\n",
      "        1.48587491, 1.44303163, 1.4360205 ],\n",
      "       [8.59665425, 1.33784318, 1.11817929, 0.95613623, 0.85566716,\n",
      "        0.90011563, 0.91441006, 0.94511562],\n",
      "       [8.59665425, 1.27244171, 1.01056561, 0.84102783, 0.77595142,\n",
      "        0.81559711, 0.84071629, 0.84588408],\n",
      "       [8.59665425, 1.15258868, 0.91071086, 0.73679183, 0.69925911,\n",
      "        0.72015239, 0.75514616, 0.77932745],\n",
      "       [8.59665425, 1.06887509, 0.85471101, 0.69533846, 0.67299786,\n",
      "        0.67522565, 0.71350092, 0.71757336],\n",
      "       [8.59665425, 1.01813741, 0.8229342 , 0.67465914, 0.6594736 ,\n",
      "        0.64668514, 0.67920209, 0.6761432 ],\n",
      "       [8.59665425, 0.94701423, 0.75577709, 0.63420993, 0.61916049,\n",
      "        0.59886678, 0.64281088, 0.64682707],\n",
      "       [8.59665425, 0.86385983, 0.6755985 , 0.59208924, 0.57592515,\n",
      "        0.55003402, 0.58597291, 0.60570183],\n",
      "       [8.59665425, 0.81019605, 0.65675269, 0.59430287, 0.57512689,\n",
      "        0.51861179, 0.54654925, 0.56423361],\n",
      "       [8.59665425, 0.76536067, 0.6226906 , 0.56508482, 0.5497247 ,\n",
      "        0.49813807, 0.51880365, 0.55327888],\n",
      "       [8.59665425, 0.75546654, 0.56847601, 0.56881728, 0.48750506,\n",
      "        0.49248034, 0.49995464, 0.55376218],\n",
      "       [8.59665425, 0.67528374, 0.55658126, 0.56646924, 0.4644027 ,\n",
      "        0.50269642, 0.47664827, 0.56296862],\n",
      "       [8.59665425, 0.64610887, 0.53791721, 0.56770796, 0.47341936,\n",
      "        0.51482051, 0.4630863 , 0.57981684],\n",
      "       [8.59665425, 0.63023419, 0.53210057, 0.56415033, 0.46992262,\n",
      "        0.5098914 , 0.47005726, 0.58421113],\n",
      "       [8.59665425, 0.53307562, 0.5161988 , 0.55437815, 0.4644659 ,\n",
      "        0.49580354, 0.46013669, 0.49258903],\n",
      "       [8.59665425, 0.52324411, 0.51859394, 0.55013018, 0.47194686,\n",
      "        0.49112998, 0.45951779, 0.49687491]]), 'first_val_acc': []}, 'True': {'first_val_loss': array([[8.59665425, 1.76494619, 1.66819267, 1.52187856, 1.45744146,\n",
      "        1.48587491, 1.44303163, 1.4360205 ],\n",
      "       [8.59665425, 1.57489053, 1.20360066, 1.08079957, 1.00822567,\n",
      "        1.01284906, 0.9921258 , 0.994246  ],\n",
      "       [8.59665425, 1.52643447, 1.12104325, 0.96583722, 0.86241536,\n",
      "        0.86574965, 0.85824389, 0.87440619],\n",
      "       [8.59665425, 1.45953482, 1.01700864, 0.87252629, 0.77419629,\n",
      "        0.79639406, 0.8051611 , 0.82316253],\n",
      "       [8.59665425, 1.26048453, 0.94899271, 0.84496058, 0.74982619,\n",
      "        0.74982859, 0.76533421, 0.78991975],\n",
      "       [8.59665425, 1.12838818, 0.89206906, 0.79456971, 0.70524222,\n",
      "        0.71976847, 0.73565872, 0.78052852],\n",
      "       [8.59665425, 1.02873283, 0.81525061, 0.75093782, 0.67387477,\n",
      "        0.70146698, 0.75896538, 0.78300989],\n",
      "       [8.59665425, 0.96643833, 0.76693366, 0.71064088, 0.64071878,\n",
      "        0.66970919, 0.72804165, 0.76609816],\n",
      "       [8.59665425, 0.93262702, 0.75271714, 0.69747498, 0.6329573 ,\n",
      "        0.65490462, 0.71587043, 0.74799162],\n",
      "       [8.59665425, 0.90309749, 0.73538907, 0.679416  , 0.62264345,\n",
      "        0.6359307 , 0.7021351 , 0.72001724],\n",
      "       [8.59665425, 0.84892883, 0.70946302, 0.65036577, 0.5834665 ,\n",
      "        0.59737159, 0.64464272, 0.6651185 ],\n",
      "       [8.59665425, 0.72728534, 0.63528724, 0.59358858, 0.54393159,\n",
      "        0.54810459, 0.64545433, 0.60956541],\n",
      "       [8.59665425, 0.71464528, 0.61590609, 0.56977276, 0.53143669,\n",
      "        0.53146742, 0.63410991, 0.59225628],\n",
      "       [8.59665425, 0.75096986, 0.61824949, 0.56413687, 0.52911919,\n",
      "        0.49993438, 0.57092195, 0.59548174],\n",
      "       [8.59665425, 0.51235239, 0.51974581, 0.54866653, 0.47677486,\n",
      "        0.48998968, 0.45737585, 0.49785254],\n",
      "       [8.59665425, 0.52324411, 0.51859394, 0.55013018, 0.47194686,\n",
      "        0.49112998, 0.45951779, 0.49687491]]), 'first_val_acc': []}}\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "for task in tasks:\n",
    "    for key in alpha_asc:\n",
    "        for layer in layers:\n",
    "            path = f\"C:/Ebooks/code/BertFt/task_{task}/lay_norm_False/alpha_asc_{key}/layers_{layer}/lr2e-5_epoch3_bs32/baseline.npy\"\n",
    "            data = np.load(path, allow_pickle=True).item()\n",
    "            dictionary[key]['first_val_loss'].append(data['val_loss_base'])\n",
    "            # dictionary[key]['first_val_acc'].append(data['val_acc_base'])\n",
    "        dictionary[key]['first_val_loss'] = np.array(dictionary[key]['first_val_loss']) # type: ignore\n",
    "        # dictionary[key]['first_val_acc'] = np.array(dictionary[key]['first_val_acc']) # type: ignore\n",
    "    \n",
    "    for i in range(1,epochs,1):\n",
    "        df_desc = pd.DataFrame(dictionary[\"False\"][\"first_val_loss\"][:, i]) # type: ignore\n",
    "        df_asc = pd.DataFrame(dictionary[\"True\"][\"first_val_loss\"][:, i]) # type: ignore\n",
    "        df = pd.concat([df_desc, df_asc], axis=1)\n",
    "        df = df.T\n",
    "        df.columns = layers\n",
    "        # rotate df\n",
    "        pth = f\"C:/Ebooks/code/BertFt/task_{task}/lay_norm_False/raw/ep_{i}/raw_val_loss.csv\"\n",
    "        #make dir if not exists\n",
    "        if not os.path.exists(os.path.dirname(pth)):\n",
    "            os.makedirs(os.path.dirname(pth))\n",
    "        df.to_csv(pth, index=False)\n",
    "    dictionary.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv with two rows called alpha_asc_True and alpha_asc_False and columns as layers\n",
    "# Each cell contains the validation loss for that layer\n",
    "# Save csv in the same folder as the .npy files\n",
    "\n",
    "for task in tasks:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
